{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting all PDF URLs (1 level deep) from a single URL passed as parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def get_base_url(url):\n",
    "    # Extract the base url: protocol, subdomain, and domain\n",
    "    base_re = r'^.+?[^\\/:](?=[?\\/]|$)'\n",
    "    return re.findall(base_re, url)[0]\n",
    "\n",
    "def get_pdf_urls(url):\n",
    "    # Extract the base url: protocol, subdomain, and domain\n",
    "    base_url = get_base_url(url)\n",
    "    \n",
    "    # Stop processing if the request wasn't successful\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        return set()\n",
    "    \n",
    "    # Extract all a-tags from the website HTML\n",
    "    bs = BeautifulSoup(r.content)\n",
    "    a_tags =  bs.findAll('a')\n",
    "    \n",
    "    # Loop through the a-tags saving all href attributes that end with .pdf\n",
    "    hrefs = []\n",
    "    for tag in a_tags:\n",
    "        if 'href' in tag.attrs.keys() and tag.attrs['href'].endswith('.pdf'):\n",
    "            hrefs.append(tag.attrs['href'])\n",
    "    \n",
    "    # Convert all hrefs to URLs by adding the base URL if required\n",
    "    pdf_links = [href if href.startswith('http') else base_url + href for href in hrefs]\n",
    "    return set(pdf_links)\n",
    "\n",
    "def get_urls(url):\n",
    "    # Extract the base url: protocol, subdomain, and domain\n",
    "    base_url = get_base_url(url)\n",
    "    \n",
    "    # Stop processing if the request wasn't successful\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        return\n",
    "    \n",
    "    # Extract all a-tags from the website HTML\n",
    "    bs = BeautifulSoup(r.content)\n",
    "    a_tags =  bs.findAll('a')\n",
    "    \n",
    "    # Extract content of href attribute from the a-tags and convert them into proper URLs using the base url\n",
    "    hrefs = {tag.attrs['href'] for tag in a_tags if 'href' in tag.attrs.keys()}\n",
    "    hrefs = {href if href.startswith('http') else base_url + href for href in hrefs}\n",
    "    \n",
    "    # Return only URLs that don't end with .pdf and that start with the base URL\n",
    "    return {href for href in hrefs if href.startswith(base_url) and not href.endswith('.pdf')}\n",
    "\n",
    "def extract_pdf_urls_from_url(url, levels = 1):\n",
    "    # Get all pdf URLs and other URLs\n",
    "    pdf_urls = get_pdf_urls(url)\n",
    "    other_urls = get_urls(url)\n",
    "    \n",
    "    # Loop through the other URLs extracting PDF URLs from each one of them\n",
    "    if levels > 0:\n",
    "        for i, url in enumerate(other_urls):\n",
    "            print(f\"{i+1}/{len(other_urls)} (#PDFs until now: {len(pdf_urls)}): {url}\")\n",
    "            pdfs_inside_url = get_pdf_urls(url)\n",
    "            pdf_urls.update(pdfs_inside_url)\n",
    "    \n",
    "    # Return the list of all PDF URLs\n",
    "    return pdf_urls\n",
    "\n",
    "def download_pdfs(urls, save_path):\n",
    "    # Create/Save path where to store all PDFs\n",
    "    path = Path(save_path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Loop through the set of PDF URLs, get its content and save the files\n",
    "    for i, pdf_url in enumerate(urls):\n",
    "        file = Path(str(i) + \".pdf\")\n",
    "        r = requests.get(pdf_url, stream=True)\n",
    "        with open(path.joinpath(file), 'wb') as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "url = 'https://www.cibc.com/en/about-cibc/investor-relations/quarterly-results.html'\n",
    "pdf_urls = extract_pdf_urls_from_url(url, levels=0)\n",
    "# download_pdfs(pdf_urls, 'data/test/path')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
