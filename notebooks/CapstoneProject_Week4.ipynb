{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d705c47-47a9-4fe3-b0aa-42e102be800b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "def get_base_url(url):\n",
    "    # Extract the base url: protocol, subdomain, and domain\n",
    "    base_re = r'^.+?[^\\/:](?=[?\\/]|$)'\n",
    "    return re.findall(base_re, url)[0]\n",
    "\n",
    "def get_pdf_urls(url):\n",
    "    # Extract the base url: protocol, subdomain, and domain\n",
    "    base_url = get_base_url(url)\n",
    "    \n",
    "    # Stop processing if the request wasn't successful\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except:\n",
    "        return set()\n",
    "    \n",
    "    if r.status_code != 200:\n",
    "        return set()\n",
    "    \n",
    "    # Extract all a-tags from the website HTML\n",
    "    bs = BeautifulSoup(r.content)\n",
    "    a_tags =  bs.findAll('a')\n",
    "    \n",
    "    # Loop through the a-tags saving all href attributes that end with .pdf\n",
    "    hrefs = []\n",
    "    for tag in a_tags:\n",
    "        if 'href' in tag.attrs.keys() and tag.attrs['href'].endswith('.pdf'):\n",
    "            hrefs.append(tag.attrs['href'])\n",
    "    \n",
    "    # Convert all hrefs to URLs by adding the base URL if required\n",
    "    pdf_links = {href if href.startswith('http') else base_url + href for href in hrefs}\n",
    "    \n",
    "    return pdf_links\n",
    "\n",
    "def download_pdfs(urls, save_path, print_details=False):\n",
    "    # Create/Save path where to store all PDFs\n",
    "    path = Path(save_path)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Loop through the set of PDF URLs, get its content and save the files\n",
    "    for i, pdf_url in enumerate(urls):\n",
    "        original_filename = os.path.basename(pdf_url).split('/')[-1]\n",
    "        rand_num = str(random.randrange(100000,199999))\n",
    "        new_filename = original_filename[:-4] + '_' + rand_num + original_filename[-4:]\n",
    "        file = Path(new_filename)\n",
    "        if print_details:\n",
    "            print(f\"Downloading ({i+1}/{len(urls)}) PDF... \", end=\"\")\n",
    "        try:\n",
    "            r = requests.get(pdf_url, stream=True)\n",
    "        except:\n",
    "            print(\"Error... \" + pdf_url)\n",
    "            continue\n",
    "        if r.status_code != 200:\n",
    "            print()\n",
    "            continue\n",
    "            \n",
    "        with open(path.joinpath(file), 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        if print_details:\n",
    "            print(\"Successful... \" + new_filename)\n",
    "            \n",
    "def get_urls(url):\n",
    "    # Extract the base url: protocol, subdomain, and domain\n",
    "    base_url = get_base_url(url)\n",
    "    \n",
    "    # Stop processing if the request wasn't successful\n",
    "    r = requests.get(url)\n",
    "    if r.status_code != 200:\n",
    "        return set()\n",
    "    \n",
    "    # Extract all a-tags from the website HTML\n",
    "    bs = BeautifulSoup(r.content)\n",
    "    a_tags =  bs.findAll('a')\n",
    "    \n",
    "    # Extract content of href attribute from the a-tags and convert them into proper URLs using the base url\n",
    "    hrefs = {tag.attrs['href'] for tag in a_tags if 'href' in tag.attrs.keys()}\n",
    "    hrefs = {href if href.startswith('http') else base_url + href for href in hrefs}\n",
    "    \n",
    "    # Return only URLs that don't end with .pdf and that start with the base URL\n",
    "    return {href for href in hrefs if href.startswith(base_url) and not href.endswith('.pdf')}\n",
    "\n",
    "def extract_pdf_urls_from_url_recursive(url, save_path, remaining_levels, original_levels, print_details=False):\n",
    "    # Get all PDF URLs\n",
    "    pdf_urls = get_pdf_urls(url)\n",
    "    \n",
    "    # Print PDFs found in the main source\n",
    "    if remaining_levels == original_levels and print_details:\n",
    "        print( f\"Depth Level 0 (Main Source) -> {len(pdf_urls)} PDFs found -> Source: {url}\")\n",
    "    \n",
    "    # Download PDFs\n",
    "    download_pdfs(pdf_urls, save_path, print_details)\n",
    "    \n",
    "    # If there's no remaining levels to dive, just return the PDF URLs found\n",
    "    if remaining_levels == 0:\n",
    "        return pdf_urls\n",
    "    \n",
    "    # Loop through the other URLs extracting PDF URLs from each one of them\n",
    "    remaining_levels -= 1\n",
    "    other_urls = get_urls(url)\n",
    "    all_pdf_urls = set()\n",
    "    for i, url_inside in enumerate(other_urls):\n",
    "        pdfs_inside = extract_pdf_urls_from_url_recursive(url_inside, save_path, remaining_levels, original_levels, print_details)\n",
    "        all_pdf_urls.update(pdfs_inside)\n",
    "        depth_level = original_levels - remaining_levels\n",
    "        if not print_details: continue\n",
    "        print(\"...\"*(depth_level-1) + f\"Depth Level {depth_level} -> {i+1}/{len(other_urls)} URLs -> {len(all_pdf_urls)} PDFs found until now -> Source: {url_inside}\")\n",
    "    \n",
    "    # Return the list of all PDF URLs found\n",
    "    all_pdf_urls.update(pdf_urls)\n",
    "    return all_pdf_urls\n",
    "\n",
    "def extract_pdf_urls_from_url(url, levels, save_path, print_details=False):\n",
    "    return extract_pdf_urls_from_url_recursive(url, save_path, remaining_levels=levels, original_levels=levels, print_details=print_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c222fe5-1a99-40be-8e34-ac51bd74cd59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading (1/638) PDF... Successful... q419factsheet-en_115876.pdf\n",
      "Downloading (2/638) PDF... Successful... q423newsrelease-en_188362.pdf\n",
      "Downloading (3/638) PDF... Successful... q220disclosure-en_146851.pdf\n",
      "Downloading (4/638) PDF... Successful... q223financials-en_151615.pdf\n",
      "Downloading (5/638) PDF... Successful... q319presentation-en_142034.pdf\n",
      "Downloading (6/638) PDF... Successful... q318financials-en_174409.pdf\n",
      "Downloading (7/638) PDF... Successful... q207dividend_107924.pdf\n",
      "Downloading (8/638) PDF... Successful... q113financials_171239.pdf\n",
      "Downloading (9/638) PDF... Error... https://www.cibc.com/content/dam/about_cibc/investor_relations/pdfs/quarterly_results/2005/q105newsrelease.pdf\n",
      "Downloading (10/638) PDF... Successful... q115hlts_196223.pdf\n",
      "Downloading (11/638) PDF... Successful... q110financials_116349.pdf\n",
      "Downloading (12/638) PDF... Successful... q412faq-en_192150.pdf\n",
      "Downloading (13/638) PDF... "
     ]
    }
   ],
   "source": [
    "cibc_link = 'https://www.cibc.com/en/about-cibc/investor-relations/quarterly-results.html'\n",
    "extract_pdf_urls_from_url(cibc_link, 2, 'data/ap3', print_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f36b5-67bd-409f-ae38-5e58737441cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Main Source #1: https://www.cibc.com/en/about-cibc/investor-relations/quarterly-results.html\n",
      "Depth Level 0 (Main Source) -> 638 PDFs found -> Source: https://www.cibc.com/en/about-cibc/investor-relations/quarterly-results.html\n",
      "Downloading (1/638) PDF... Successful... q209factsheet_161419.pdf\n",
      "Downloading (2/638) PDF... Successful... q306presentation_178580.pdf\n",
      "Downloading (3/638) PDF... Successful... q319financials-en_192069.pdf\n",
      "Downloading (4/638) PDF... Successful... q118hlts-en_195208.pdf\n",
      "Downloading (5/638) PDF... Successful... q308factsheet_140870.pdf\n",
      "Downloading (6/638) PDF... Successful... q220dividend-en_163944.pdf\n",
      "Downloading (7/638) PDF... Successful... q212report_160382.pdf\n",
      "Downloading (8/638) PDF... Successful... q413financials_139376.pdf\n",
      "Downloading (9/638) PDF... Successful... q110faq_115343.pdf\n",
      "Downloading (10/638) PDF... Successful... q120hlts-en_169473.pdf\n",
      "Downloading (11/638) PDF... Successful... q416presentation-en_143743.pdf\n",
      "Downloading (12/638) PDF... Successful... q316factsheet-en_112947.pdf\n",
      "Downloading (13/638) PDF... Successful... q415factsheet_165980.pdf\n",
      "Downloading (14/638) PDF... Successful... q221-transcript-en_148424.pdf\n",
      "Downloading (15/638) PDF... Successful... q106faq-en_182869.pdf\n",
      "Downloading (16/638) PDF... Successful... q319disclosure-en_146260.pdf\n",
      "Downloading (17/638) PDF... Successful... q123report-en_102667.pdf\n",
      "Downloading (18/638) PDF... Successful... q423newsrelease-en_126794.pdf\n",
      "Downloading (19/638) PDF... Successful... q420financials-en_147406.pdf\n",
      "Downloading (20/638) PDF... Successful... q107factsheet_152548.pdf\n",
      "Downloading (21/638) PDF... Successful... q405dividend_134615.pdf\n",
      "Downloading (22/638) PDF... Successful... q309dividend_122840.pdf\n",
      "Downloading (23/638) PDF... Successful... q323factsheet-en_168059.pdf\n",
      "Downloading (24/638) PDF... Successful... q105presentation_166743.pdf\n",
      "Downloading (25/638) PDF... Successful... q208hlts_137515.pdf\n",
      "Downloading (26/638) PDF... Successful... 2011-financial-results_130145.pdf\n",
      "Downloading (27/638) PDF... Successful... q220factsheet-en_152166.pdf\n",
      "Downloading (28/638) PDF... Successful... q306faq-en_114266.pdf\n",
      "Downloading (29/638) PDF... Successful... q307newsrelease_114759.pdf\n",
      "Downloading (30/638) PDF... Successful... q419factsheet-en_108312.pdf\n",
      "Downloading (31/638) PDF... Successful... q410newsrelease_192288.pdf\n",
      "Downloading (32/638) PDF... Successful... q312factsheet_183129.pdf\n",
      "Downloading (33/638) PDF... Successful... ar-19-en_196178.pdf\n",
      "Downloading (34/638) PDF... Successful... q415newsrelease_138911.pdf\n",
      "Downloading (35/638) PDF... Error... https://www.cibc.com/content/dam/about_cibc/investor_relations/pdfs/quarterly_results/2021/q321newsrelease-en.pdf\n",
      "Downloading (36/638) PDF... Successful... q313dividend_191585.pdf\n",
      "Downloading (37/638) PDF... Successful... q420hlts-en_187470.pdf\n",
      "Downloading (38/638) PDF... "
     ]
    }
   ],
   "source": [
    "def download_pdfs_from_source_txt(source_path, save_path, levels, print_details):\n",
    "    proper_source_path = Path(source_path)\n",
    "    proper_save_path = Path(save_path)\n",
    "    \n",
    "    source_txt = open(proper_source_path)\n",
    "    \n",
    "    for i, line in enumerate(source_txt):\n",
    "        link = line.strip()\n",
    "        if print_details:\n",
    "            print(f\"Extracting Main Source #{i+1}: {link}\")\n",
    "        extract_pdf_urls_from_url(link, levels, proper_save_path, print_details=print_details)\n",
    "    \n",
    "    source_txt.close()\n",
    "    \n",
    "download_pdfs_from_source_txt('sources.txt', 'data/ap', levels=1, print_details=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
